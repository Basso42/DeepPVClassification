{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Préparation des données"
      ],
      "metadata": {
        "id": "dyycN7Y3nItV"
      },
      "id": "dyycN7Y3nItV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montage google drive et décompression des données de bdappv.zip"
      ],
      "metadata": {
        "id": "s-FjgO3hm1Z9"
      },
      "id": "s-FjgO3hm1Z9"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "#sys.path.insert(0,'/content/drive/My Drive/statapps-main/src/')\n",
        "!unzip /content/drive/MyDrive/bdappv/bdappv.zip > /dev/null"
      ],
      "metadata": {
        "id": "6m5MJtMnYHLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f96fcb-3b21-428d-f937-239919525b24"
      },
      "id": "6m5MJtMnYHLD",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importation du fichier dataloader pour pouvoir utiliser ses modules"
      ],
      "metadata": {
        "id": "dzG3HEtemNrj"
      },
      "id": "dzG3HEtemNrj"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/statapps-main/src/dataloader.py /content"
      ],
      "metadata": {
        "id": "KDqq9URoPmcc"
      },
      "id": "KDqq9URoPmcc",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "802b66ca-ba33-4a4d-9545-8e49e1142b53",
      "metadata": {
        "id": "802b66ca-ba33-4a4d-9545-8e49e1142b53"
      },
      "outputs": [],
      "source": [
        "import dataloader as dtld"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "metadata": {
        "id": "c4R37Bj0pf1r"
      },
      "id": "c4R37Bj0pf1r",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1aece920-7233-4d20-bbab-a8c9852a8c98",
      "metadata": {
        "id": "1aece920-7233-4d20-bbab-a8c9852a8c98"
      },
      "outputs": [],
      "source": [
        "label_attribution = dtld.LabelAttribution(path_image_google='/content/bdappv/google/img', \n",
        "                                   path_mask_google='/content/bdappv/google/mask',\n",
        "                                   path_metadata='/content/bdappv/metadata.csv',\n",
        "                                   colonne_identifiant='identifiant',\n",
        "                                   path_export_train_test='/content/drive/MyDrive',\n",
        "                                   path_image_ign='/content/bdappv/ign/img',\n",
        "                                   path_mask_ign='/content/bdappv/ign/mask',\n",
        "                                   use_img_google=True,\n",
        "                                   use_img_ign=False\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fda5351c-aa4d-44b6-8516-adfc0a2a95d8",
      "metadata": {
        "id": "fda5351c-aa4d-44b6-8516-adfc0a2a95d8"
      },
      "outputs": [],
      "source": [
        "label_attribution.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_train='/content/drive/MyDrive/train_data.csv'\n",
        "path_test='/content/drive/MyDrive/test_data.csv'\n",
        "\n",
        "transformed_train_dataset  = dtld.CustomImageDataset(path_train,'/content/bdappv/google/img', transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor()\n",
        "                                           ]))\n",
        "transformed_test_dataset = dtld.CustomImageDataset(path_test,\"/content/bdappv/google/img\",\n",
        "                                                transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                           ]))"
      ],
      "metadata": {
        "id": "J4AOt07MoDTP"
      },
      "id": "J4AOt07MoDTP",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Nombre d'images dans le train: {}\".format(transformed_train_dataset.__len__()))\n",
        "print(\"Nombre d'images dans le test: {}\".format(transformed_test_dataset.__len__()))"
      ],
      "metadata": {
        "id": "41Sfxd_uq7LT",
        "outputId": "ac98b211-7f0b-4d92-b987-8b01b0cad273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "41Sfxd_uq7LT",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'images dans le train: 23045\n",
            "Nombre d'images dans le test: 5762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(transformed_train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(transformed_test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "tQyPLEJRsPUa"
      },
      "id": "tQyPLEJRsPUa",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_train, std_train = dtld.mean_std(train_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean_train.tolist()))\n",
        "print(\"Ecart-type par channel: {}\".format(std_train.tolist()))"
      ],
      "metadata": {
        "id": "tUmWHYM9YAGX",
        "outputId": "7e352f2d-49d6-449c-8795-eb6be6f62549",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tUmWHYM9YAGX",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moyenne par channel: [0.35261356830596924, 0.3558049499988556, 0.3049164414405823]\n",
            "Ecart-type par channel: [0.20973347127437592, 0.19094730913639069, 0.18523310124874115]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_test, std_test = dtld.mean_std(test_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean_test.tolist()))\n",
        "print(\"Ecart-type par channel: {}\".format(std_test.tolist()))"
      ],
      "metadata": {
        "id": "nlUXzSHNYApX",
        "outputId": "f4afe7a0-e769-43c8-b881-5db8821c8918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nlUXzSHNYApX",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moyenne par channel: [0.3499608635902405, 0.3598434329032898, 0.3147274851799011]\n",
            "Ecart-type par channel: [0.20578326284885406, 0.18819521367549896, 0.18261423707008362]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_train_dataset  = dtld.CustomImageDataset(path_train,'/content/bdappv/google/img', transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(mean = mean_train.tolist(),\n",
        "                                                                    std= std_train.tolist()),\n",
        "                                               transforms.RandomHorizontalFlip(),\n",
        "                                           ]))\n",
        "\n",
        "normalized_test_dataset  = dtld.CustomImageDataset(path_test,\"/content/bdappv/google/img\", transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(mean = mean_test.tolist(),\n",
        "                                                                    std= std_test.tolist()),\n",
        "                                               transforms.RandomHorizontalFlip(),\n",
        "                                           ]))\n",
        "\n",
        "train_dataloader = DataLoader(normalized_train_dataset, batch_size=64, shuffle=False)\n",
        "test_dataloader = DataLoader(normalized_test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "zZ0PNnaFZkjN"
      },
      "id": "zZ0PNnaFZkjN",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Implémentation ResNet18"
      ],
      "metadata": {
        "id": "yGfakcfMsW1P"
      },
      "id": "yGfakcfMsW1P"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "72bb89b7-50e4-40f3-9fce-485d6ae8cc27",
      "metadata": {
        "id": "72bb89b7-50e4-40f3-9fce-485d6ae8cc27"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "I_xeQlwUwW60"
      },
      "id": "I_xeQlwUwW60",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "uo6qEEXgvBAs"
      },
      "id": "uo6qEEXgvBAs",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion des données en array numpy "
      ],
      "metadata": {
        "id": "3-gnFhRwlW-m"
      },
      "id": "3-gnFhRwlW-m"
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18(1)\n",
        "model.build(input_shape = (None,224 ,224 ,3))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "from keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "JtrdFze9zkMG",
        "outputId": "18bf72f7-68dd-48bc-f93c-88249cf5d2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JtrdFze9zkMG",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"res_net18_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_100 (Conv2D)         multiple                  9472      \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  multiple                 256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " resnet_block_40 (ResnetBloc  multiple                 74368     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_41 (ResnetBloc  multiple                 74368     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_42 (ResnetBloc  multiple                 231296    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_43 (ResnetBloc  multiple                 296192    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_44 (ResnetBloc  multiple                 921344    \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_45 (ResnetBloc  multiple                 1182208   \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_46 (ResnetBloc  multiple                 3677696   \n",
            " k)                                                              \n",
            "                                                                 \n",
            " resnet_block_47 (ResnetBloc  multiple                 4723712   \n",
            " k)                                                              \n",
            "                                                                 \n",
            " global_average_pooling2d_5   multiple                 0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             multiple                  513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,191,425\n",
            "Trainable params: 11,181,825\n",
            "Non-trainable params: 9,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train=next(iter(train_dataloader))\n",
        "X_test, Y_test=next(iter(test_dataloader))"
      ],
      "metadata": {
        "id": "FbfFv3lupyUU"
      },
      "id": "FbfFv3lupyUU",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_permute=X_train.permute(0, 2, 3,1)\n",
        "X_test_permute=X_test.permute(0, 2, 3,1)"
      ],
      "metadata": {
        "id": "6AJudF_coekW"
      },
      "id": "6AJudF_coekW",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train_permute.numpy(), y=Y_train.numpy(),\n",
        "\tvalidation_data=(X_test_permute.numpy(), Y_test.numpy()),\n",
        "\tbatch_size=64,\n",
        "\tepochs=3)"
      ],
      "metadata": {
        "id": "3r6zNGvlnkt3",
        "outputId": "6f99a12e-7e47-4416-a22e-03465b250bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "id": "3r6zNGvlnkt3",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-2fb4f22a8aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(x=X_train_permute.numpy(), y=Y_train.numpy(),\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_permute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \tepochs=3)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, recall, precision, f1score = model_init.evaluate(X_test_permute.numpy(), Y_test.numpy(), verbose=0)\n",
        "print(\"Loss sur l'échantillon test: {}\".format(round(loss,3)))\n",
        "print(\"Accuracy sur l'échantillon test: {}\".format(round(accuracy,3)))\n",
        "print(\"Recall sur l'échantillon test: {}\".format(round(recall,3)))\n",
        "print(\"Precision sur l'échantillon test: {}\".format(round(precision,3)))\n",
        "print(\"F1-score sur l'échantillon test: {}\".format(round(f1score,3)))"
      ],
      "metadata": {
        "id": "TC8-oY5DwVC5"
      },
      "id": "TC8-oY5DwVC5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}