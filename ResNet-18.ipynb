{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Préparation des données"
      ],
      "metadata": {
        "id": "dyycN7Y3nItV"
      },
      "id": "dyycN7Y3nItV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montage google drive et décompression des données de bdappv.zip"
      ],
      "metadata": {
        "id": "s-FjgO3hm1Z9"
      },
      "id": "s-FjgO3hm1Z9"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "#sys.path.insert(0,'/content/drive/My Drive/statapps-main/src/')\n",
        "!unzip /content/drive/MyDrive/bdappv/bdappv.zip > /dev/null"
      ],
      "metadata": {
        "id": "6m5MJtMnYHLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0e8809-635a-42b4-ac81-5cb4b40a11a4"
      },
      "id": "6m5MJtMnYHLD",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "replace __MACOSX/._bdappv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "[A]ll\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importation du fichier dataloader pour pouvoir utiliser ses modules"
      ],
      "metadata": {
        "id": "dzG3HEtemNrj"
      },
      "id": "dzG3HEtemNrj"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/statapps-main/src/dataloader.py /content"
      ],
      "metadata": {
        "id": "KDqq9URoPmcc"
      },
      "id": "KDqq9URoPmcc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "802b66ca-ba33-4a4d-9545-8e49e1142b53",
      "metadata": {
        "id": "802b66ca-ba33-4a4d-9545-8e49e1142b53"
      },
      "outputs": [],
      "source": [
        "import dataloader as dtld\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "metadata": {
        "id": "c4R37Bj0pf1r"
      },
      "id": "c4R37Bj0pf1r",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1aece920-7233-4d20-bbab-a8c9852a8c98",
      "metadata": {
        "id": "1aece920-7233-4d20-bbab-a8c9852a8c98"
      },
      "outputs": [],
      "source": [
        "label_attribution = dtld.LabelAttribution(path_image_google='/content/bdappv/google/img', \n",
        "                                   path_mask_google='/content/bdappv/google/mask',\n",
        "                                   path_metadata='/content/bdappv/metadata.csv',\n",
        "                                   colonne_identifiant='identifiant',\n",
        "                                   path_export_train_test='/content/drive/MyDrive',\n",
        "                                   path_image_ign='/content/bdappv/ign/img',\n",
        "                                   path_mask_ign='/content/bdappv/ign/mask',\n",
        "                                   use_img_google=True,\n",
        "                                   use_img_ign=False\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "fda5351c-aa4d-44b6-8516-adfc0a2a95d8",
      "metadata": {
        "id": "fda5351c-aa4d-44b6-8516-adfc0a2a95d8"
      },
      "outputs": [],
      "source": [
        "label_attribution.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_train='/content/drive/MyDrive/train_data.csv'\n",
        "path_test='/content/drive/MyDrive/test_data.csv'\n",
        "\n",
        "transformed_train_dataset  = dtld.CustomImageDataset(path_train,'/content/bdappv/google/img', transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor()\n",
        "                                           ]))\n",
        "transformed_test_dataset = dtld.CustomImageDataset(path_test,\"/content/bdappv/google/img\",\n",
        "                                                transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                           ]))"
      ],
      "metadata": {
        "id": "J4AOt07MoDTP"
      },
      "id": "J4AOt07MoDTP",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Nombre d'images dans le train: {}\".format(transformed_train_dataset.__len__()))\n",
        "print(\"Nombre d'images dans le test: {}\".format(transformed_test_dataset.__len__()))"
      ],
      "metadata": {
        "id": "41Sfxd_uq7LT",
        "outputId": "546d256f-7a70-4853-87b8-11a535a143b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "41Sfxd_uq7LT",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'images dans le train: 23045\n",
            "Nombre d'images dans le test: 5762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataloader = DataLoader(transformed_train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(transformed_test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "tQyPLEJRsPUa"
      },
      "id": "tQyPLEJRsPUa",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Implémentation ResNet18"
      ],
      "metadata": {
        "id": "yGfakcfMsW1P"
      },
      "id": "yGfakcfMsW1P"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "72bb89b7-50e4-40f3-9fce-485d6ae8cc27",
      "metadata": {
        "id": "72bb89b7-50e4-40f3-9fce-485d6ae8cc27"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "uo6qEEXgvBAs"
      },
      "id": "uo6qEEXgvBAs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18(12)\n",
        "model.build(input_shape = (None,img_shape,img_shape,3))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "from keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "JtrdFze9zkMG"
      },
      "id": "JtrdFze9zkMG",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}