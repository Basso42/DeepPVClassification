{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Préparation des données"
      ],
      "metadata": {
        "id": "dyycN7Y3nItV"
      },
      "id": "dyycN7Y3nItV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montage google drive et décompression des données de bdappv.zip"
      ],
      "metadata": {
        "id": "s-FjgO3hm1Z9"
      },
      "id": "s-FjgO3hm1Z9"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "#sys.path.insert(0,'/content/drive/My Drive/statapps-main/src/')\n",
        "!unzip /content/drive/MyDrive/bdappv/bdappv.zip > /dev/null"
      ],
      "metadata": {
        "id": "6m5MJtMnYHLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f96fcb-3b21-428d-f937-239919525b24"
      },
      "id": "6m5MJtMnYHLD",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importation du fichier dataloader pour pouvoir utiliser ses modules"
      ],
      "metadata": {
        "id": "dzG3HEtemNrj"
      },
      "id": "dzG3HEtemNrj"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/statapps-main/src/dataloader.py /content"
      ],
      "metadata": {
        "id": "KDqq9URoPmcc"
      },
      "id": "KDqq9URoPmcc",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "802b66ca-ba33-4a4d-9545-8e49e1142b53",
      "metadata": {
        "id": "802b66ca-ba33-4a4d-9545-8e49e1142b53"
      },
      "outputs": [],
      "source": [
        "import dataloader as dtld"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "metadata": {
        "id": "c4R37Bj0pf1r"
      },
      "id": "c4R37Bj0pf1r",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1aece920-7233-4d20-bbab-a8c9852a8c98",
      "metadata": {
        "id": "1aece920-7233-4d20-bbab-a8c9852a8c98"
      },
      "outputs": [],
      "source": [
        "label_attribution = dtld.LabelAttribution(path_image_google='/content/bdappv/google/img', \n",
        "                                   path_mask_google='/content/bdappv/google/mask',\n",
        "                                   path_metadata='/content/bdappv/metadata.csv',\n",
        "                                   colonne_identifiant='identifiant',\n",
        "                                   path_export_train_test='/content/drive/MyDrive',\n",
        "                                   path_image_ign='/content/bdappv/ign/img',\n",
        "                                   path_mask_ign='/content/bdappv/ign/mask',\n",
        "                                   use_img_google=True,\n",
        "                                   use_img_ign=False\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fda5351c-aa4d-44b6-8516-adfc0a2a95d8",
      "metadata": {
        "id": "fda5351c-aa4d-44b6-8516-adfc0a2a95d8"
      },
      "outputs": [],
      "source": [
        "label_attribution.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_train='/content/drive/MyDrive/train_data.csv'\n",
        "path_test='/content/drive/MyDrive/test_data.csv'\n",
        "\n",
        "transformed_train_dataset  = dtld.CustomImageDataset(path_train,'/content/bdappv/google/img', transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor()\n",
        "                                           ]))\n",
        "transformed_test_dataset = dtld.CustomImageDataset(path_test,\"/content/bdappv/google/img\",\n",
        "                                                transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                           ]))"
      ],
      "metadata": {
        "id": "J4AOt07MoDTP"
      },
      "id": "J4AOt07MoDTP",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Nombre d'images dans le train: {}\".format(transformed_train_dataset.__len__()))\n",
        "print(\"Nombre d'images dans le test: {}\".format(transformed_test_dataset.__len__()))"
      ],
      "metadata": {
        "id": "41Sfxd_uq7LT",
        "outputId": "ac98b211-7f0b-4d92-b987-8b01b0cad273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "41Sfxd_uq7LT",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'images dans le train: 23045\n",
            "Nombre d'images dans le test: 5762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(transformed_train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(transformed_test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "tQyPLEJRsPUa"
      },
      "id": "tQyPLEJRsPUa",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_train, std_train = dtld.mean_std(train_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean_train.tolist()))\n",
        "print(\"Ecart-type par channel: {}\".format(std_train.tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUmWHYM9YAGX",
        "outputId": "7e352f2d-49d6-449c-8795-eb6be6f62549"
      },
      "id": "tUmWHYM9YAGX",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moyenne par channel: [0.35261356830596924, 0.3558049499988556, 0.3049164414405823]\n",
            "Ecart-type par channel: [0.20973347127437592, 0.19094730913639069, 0.18523310124874115]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_test, std_test = dtld.mean_std(test_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean_test.tolist()))\n",
        "print(\"Ecart-type par channel: {}\".format(std_test.tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlUXzSHNYApX",
        "outputId": "f4afe7a0-e769-43c8-b881-5db8821c8918"
      },
      "id": "nlUXzSHNYApX",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moyenne par channel: [0.3499608635902405, 0.3598434329032898, 0.3147274851799011]\n",
            "Ecart-type par channel: [0.20578326284885406, 0.18819521367549896, 0.18261423707008362]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_train_dataset  = dtld.CustomImageDataset(path_train,'/content/bdappv/google/img', transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(mean = mean_train.tolist(),\n",
        "                                                                    std= std_train.tolist()),\n",
        "                                               transforms.RandomHorizontalFlip(),\n",
        "                                           ]))\n",
        "\n",
        "normalized_test_dataset  = dtld.CustomImageDataset(path_test,\"/content/bdappv/google/img\", transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(mean = mean_test.tolist(),\n",
        "                                                                    std= std_test.tolist()),\n",
        "                                               transforms.RandomHorizontalFlip(),\n",
        "                                           ]))\n",
        "\n",
        "train_dataloader = DataLoader(normalized_train_dataset, batch_size=64, shuffle=False)\n",
        "test_dataloader = DataLoader(normalized_test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "zZ0PNnaFZkjN"
      },
      "id": "zZ0PNnaFZkjN",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Implémentation ResNet18"
      ],
      "metadata": {
        "id": "yGfakcfMsW1P"
      },
      "id": "yGfakcfMsW1P"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "72bb89b7-50e4-40f3-9fce-485d6ae8cc27",
      "metadata": {
        "id": "72bb89b7-50e4-40f3-9fce-485d6ae8cc27"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "I_xeQlwUwW60"
      },
      "id": "I_xeQlwUwW60",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "uo6qEEXgvBAs"
      },
      "id": "uo6qEEXgvBAs",
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18(2)\n",
        "model.build(input_shape = (None,224 ,224 ,3))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "from keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "model.compile(optimizer = \"adam\",loss='binary_crossentropy', metrics=[\"accuracy\",recall_m, precision_m, f1_m]) \n",
        "model.summary()"
      ],
      "metadata": {
        "id": "JtrdFze9zkMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b9f8c7-6f7a-4475-bb20-adbbed0ed34b"
      },
      "id": "JtrdFze9zkMG",
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7fd4a984a250>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7fd4a984a250>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model: \"res_net18_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_400 (Conv2D)         multiple                  9472      \n",
            "                                                                 \n",
            " batch_normalization_400 (Ba  multiple                 256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " resnet_block_160 (ResnetBlo  multiple                 74368     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " resnet_block_161 (ResnetBlo  multiple                 74368     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " resnet_block_162 (ResnetBlo  multiple                 231296    \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " resnet_block_163 (ResnetBlo  multiple                 296192    \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " resnet_block_164 (ResnetBlo  multiple                 921344    \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " resnet_block_165 (ResnetBlo  multiple                 1182208   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " resnet_block_166 (ResnetBlo  multiple                 3677696   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " resnet_block_167 (ResnetBlo  multiple                 4723712   \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d_20  multiple                 0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        multiple                  0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            multiple                  1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,191,938\n",
            "Trainable params: 11,182,338\n",
            "Non-trainable params: 9,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train=next(iter(train_dataloader))\n",
        "X_test, Y_test=next(iter(test_dataloader))"
      ],
      "metadata": {
        "id": "FbfFv3lupyUU"
      },
      "id": "FbfFv3lupyUU",
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_permute=X_train.permute(0, 2, 3,1)\n",
        "X_test_permute=X_test.permute(0, 2, 3,1)"
      ],
      "metadata": {
        "id": "6AJudF_coekW"
      },
      "id": "6AJudF_coekW",
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test.numpy())\n",
        "len(Y)"
      ],
      "metadata": {
        "id": "AIIpF7KNImsJ",
        "outputId": "e9da378f-c271-46c5-a14b-b9c938b3f3aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AIIpF7KNImsJ",
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On transforme le vecteur des labels pour qu'il correspondent au format attendu par le modèle\n",
        "\n",
        "Un vecteur de 64 lignes (la dimension du batch) et deux colonnes (car on a deux labels possibles pour nos images)."
      ],
      "metadata": {
        "id": "Gxz3Iu7baYkL"
      },
      "id": "Gxz3Iu7baYkL"
    },
    {
      "cell_type": "code",
      "source": [
        "def label_array_formatting(Y):\n",
        "  formatted_Y = np.zeros((len(Y), 2))\n",
        "  for i in range(len(Y)):\n",
        "    if Y[i] == 1:\n",
        "      formatted_Y[i][0], formatted_Y[i][1] = 0, 1\n",
        "    else:\n",
        "      formatted_Y[i][0], formatted_Y[i][1] = 1, 0\n",
        "  return formatted_Y"
      ],
      "metadata": {
        "id": "oAx1nIsaONqx"
      },
      "id": "oAx1nIsaONqx",
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lancement du modèle\n",
        "\n",
        "On convertit le tenseur en array numpy pour que le modèle keras puisse le lire"
      ],
      "metadata": {
        "id": "KsZ8iOC34rwq"
      },
      "id": "KsZ8iOC34rwq"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train_permute.numpy(), y = label_array_formatting(Y_train),\n",
        "\tvalidation_data=(X_test_permute.numpy(), label_array_formatting(Y_test)),\n",
        "\tbatch_size=64,\n",
        "\tepochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r6zNGvlnkt3",
        "outputId": "e2865934-a9d7-4444-a70f-c5cd51443aa6"
      },
      "id": "3r6zNGvlnkt3",
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 33s 33s/step - loss: 0.8327 - accuracy: 0.5156 - recall_m: 0.6562 - precision_m: 0.5000 - f1_m: 0.5676 - val_loss: 2082.7620 - val_accuracy: 0.4844 - val_recall_m: 0.4844 - val_precision_m: 0.4844 - val_f1_m: 0.4844\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 25s 25s/step - loss: 1.7409 - accuracy: 0.7188 - recall_m: 0.7188 - precision_m: 0.7188 - f1_m: 0.7187 - val_loss: 900.0911 - val_accuracy: 0.4844 - val_recall_m: 0.4844 - val_precision_m: 0.4844 - val_f1_m: 0.4844\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.7205 - accuracy: 0.6094 - recall_m: 0.6562 - precision_m: 0.6269 - f1_m: 0.6412 - val_loss: 3549.1116 - val_accuracy: 0.4844 - val_recall_m: 0.4844 - val_precision_m: 0.4844 - val_f1_m: 0.4844\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 27s 27s/step - loss: 0.5268 - accuracy: 0.8281 - recall_m: 0.7500 - precision_m: 0.8000 - f1_m: 0.7742 - val_loss: 6263.9067 - val_accuracy: 0.4844 - val_recall_m: 0.4844 - val_precision_m: 0.4844 - val_f1_m: 0.4844\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 30s 30s/step - loss: 0.3130 - accuracy: 0.8906 - recall_m: 0.8594 - precision_m: 0.8594 - f1_m: 0.8594 - val_loss: 5075.4976 - val_accuracy: 0.4844 - val_recall_m: 0.4844 - val_precision_m: 0.4844 - val_f1_m: 0.4844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd499e61640>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, recall, precision, f1score = model.evaluate(X_test_permute.numpy(), label_array_formatting(Y_test), verbose=0)\n",
        "print(\"Loss sur l'échantillon test: {}\".format(round(loss,3)))\n",
        "print(\"Accuracy sur l'échantillon test: {}\".format(round(accuracy,3)))\n",
        "print(\"Recall sur l'échantillon test: {}\".format(round(recall_m,3)))\n",
        "print(\"Precision sur l'échantillon test: {}\".format(round(precision_m,3)))\n",
        "print(\"F1-score sur l'échantillon test: {}\".format(round(f1_m,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "TC8-oY5DwVC5",
        "outputId": "65cabe2c-799d-4973-b25b-f98cee7811f5"
      },
      "id": "TC8-oY5DwVC5",
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss sur l'échantillon test: 5075.498\n",
            "Accuracy sur l'échantillon test: 0.484\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-184-7de1afc33073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss sur l'échantillon test: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy sur l'échantillon test: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall sur l'échantillon test: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision sur l'échantillon test: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1-score sur l'échantillon test: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: type function doesn't define __round__ method"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}