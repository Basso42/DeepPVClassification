{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dyycN7Y3nItV",
      "metadata": {
        "id": "dyycN7Y3nItV"
      },
      "source": [
        "# Préparation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd213552",
      "metadata": {
        "id": "fd213552"
      },
      "source": [
        "## Import et data augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c4R37Bj0pf1r",
      "metadata": {
        "id": "c4R37Bj0pf1r"
      },
      "outputs": [],
      "source": [
        "from  src.dataloader import *\n",
        "from src.metrics import *\n",
        "from src.resnet18 import *\n",
        " \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from src.confusion_matrix import make_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras.losses import BinaryCrossentropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ca516453",
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1aece920-7233-4d20-bbab-a8c9852a8c98",
      "metadata": {
        "id": "1aece920-7233-4d20-bbab-a8c9852a8c98"
      },
      "outputs": [],
      "source": [
        "label_attribution=LabelAttribution(path_image_google=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", \n",
        "                                   path_mask_google='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/mask/',\n",
        "                                   path_metadata='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/metadata.csv',\n",
        "                                   colonne_identifiant='identifiant',\n",
        "                                   path_export_train_test=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps\",\n",
        "                                   path_image_ign='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/ign/img',\n",
        "                                   path_mask_ign='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/ign/mask/',\n",
        "                                   use_img_google=True,\n",
        "                                   use_img_ign=False\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fda5351c-aa4d-44b6-8516-adfc0a2a95d8",
      "metadata": {
        "id": "fda5351c-aa4d-44b6-8516-adfc0a2a95d8"
      },
      "outputs": [],
      "source": [
        "label_attribution.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fcc608e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "path_train=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps/train_data.csv\"\n",
        "path_test=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps/test_data.csv\"\n",
        "\n",
        "transformed_train_dataset  = CustomImageDataset(path_train,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.5, 0.5)),\n",
        "                                               transforms.RandomCrop(160),\n",
        "                                               transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                               transforms.RandomVerticalFlip(p=0.5),\n",
        "                                               transforms.RandomRotation(degrees = (0,180)),\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               #transforms.Normalize(mean = [0.2969593107700348, 0.29610514640808105, 0.29613879323005676],\n",
        "                                                                    #std= [0.19015252590179443, 0.18941254913806915, 0.18982695043087006])\n",
        "\n",
        "                                           ]))\n",
        "\n",
        "#On resize et normalise uniquement sur le test\n",
        "transformed_test_dataset = CustomImageDataset(path_test,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\",\n",
        "                                            transform=transforms.Compose([\n",
        "                                               transforms.Resize(224),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               #transforms.Normalize(mean = [0.3499923348426819, 0.3576664924621582, 0.3081061840057373],\n",
        "                                                                    #std= [0.16761955618858337, 0.14885342121124268, 0.1473139077425003])\n",
        "                                           ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "41Sfxd_uq7LT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Sfxd_uq7LT",
        "outputId": "c7db8973-6837-4600-a0ba-d6664f7862d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre d'images dans le train: 23045\n",
            "Nombre d'images dans le test: 5762\n"
          ]
        }
      ],
      "source": [
        "print(\"Nombre d'images dans le train: {}\".format(transformed_train_dataset.__len__()))\n",
        "print(\"Nombre d'images dans le test: {}\".format(transformed_test_dataset.__len__()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "tQyPLEJRsPUa",
      "metadata": {
        "id": "tQyPLEJRsPUa"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(transformed_train_dataset, batch_size=23045, shuffle=True)\n",
        "test_dataloader = DataLoader(transformed_test_dataset, batch_size=5762, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a286a12b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moyenne par channel: [0.29619696736335754, 0.2954482138156891, 0.2950427234172821]\n",
            "Ecart-type par channel: [0.21924977004528046, 0.21851609647274017, 0.2186581790447235]\n"
          ]
        }
      ],
      "source": [
        "mean_train, std_train = mean_std(train_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean_train.tolist()))\n",
        "print(\"Ecart-type par channel: {}\".format(std_train.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d70b543d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moyenne par channel: [0.34992772340774536, 0.35760578513145447, 0.3080298900604248]\n",
            "Ecart-type par channel: [0.2013908326625824, 0.18425437808036804, 0.1794954240322113]\n"
          ]
        }
      ],
      "source": [
        "mean_test, std_test = mean_std(test_dataloader)\n",
        "print(\"Moyenne par channel: {}\".format(mean_test.tolist()))\n",
        "print(\"Ecart-type par channel: {}\".format(std_test.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "410985ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "normalized_train_dataset  = CustomImageDataset(path_train,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", transform=transforms.Compose([\n",
        "                                               transforms.Resize(28),\n",
        "                                               transforms.ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.5, 0.5)),\n",
        "                                               transforms.RandomCrop(20),\n",
        "                                               transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                               transforms.RandomVerticalFlip(p=0.5),\n",
        "                                               transforms.RandomRotation(degrees = (0,180)),\n",
        "                                               transforms.Resize(28),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(mean = [0.29619696736335754, 0.2954482138156891, 0.2950427234172821],\n",
        "                                                                    std= [0.21924977004528046, 0.21851609647274017, 0.2186581790447235]), \n",
        "\n",
        "                                           ]))\n",
        "\n",
        "\n",
        "normalize_test_dataset = CustomImageDataset(path_test,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\",\n",
        "                                            transform=transforms.Compose([\n",
        "                                               transforms.Resize(28),\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(mean = [0.34992772340774536, 0.35760578513145447, 0.3080298900604248],\n",
        "                                                                    std= [0.2013908326625824, 0.18425437808036804, 0.1794954240322113]), \n",
        "                                           ]))\n",
        "train_dataloader_augmente = DataLoader(normalized_train_dataset, batch_size=23045, shuffle=True)\n",
        "test_dataloader_augmente = DataLoader(normalize_test_dataset, batch_size=5762, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "50bfc8af",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, Y_train=next(iter(train_dataloader))\n",
        "X_test, Y_test=next(iter(test_dataloader))\n",
        "\n",
        "X_train_permute=X_train.permute(0, 2, 3,1)\n",
        "X_test_permute=X_test.permute(0, 2, 3,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jBWM12pxcvQK",
      "metadata": {
        "id": "jBWM12pxcvQK"
      },
      "source": [
        "# Lancement du modèle\n",
        "\n",
        "Les cinq premières métriques représentent les performances de notre algorithme sur l'échantillon d'entrainement, les cinq dernières valeurs (celles précédées du préfixe val_) sont elles calculées sur l'échantillon de test. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6e839e45",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_init = buildModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Gkds0SmvZtxN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkds0SmvZtxN",
        "outputId": "72f37518-16e4-4f61-c8f9-eb3e9aa4d306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 30/721 [>.............................] - ETA: 4:55:36 - loss: 21.8206 - Accuracy: 0.5177 - recall_m: 0.4840 - precision_m: 0.3247 - f1_m: 0.3630"
          ]
        }
      ],
      "source": [
        "history=model_init.fit(x = X_train_permute.numpy(), y = Y_train.numpy(),\n",
        "\tvalidation_data=(X_test_permute.numpy(), Y_test.numpy()),\n",
        "\tbatch_size=32,\n",
        "\tepochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3646dc59",
      "metadata": {},
      "outputs": [],
      "source": [
        "recall = history.history['recall_m']\n",
        "val_recall = history.history['val_recall_m']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(recall) + 1)\n",
        "\n",
        "plt.plot(epochs, recall, 'b', label=\"Recall sur l'échantillon d'apprentissage\")\n",
        "plt.plot(epochs, val_recall, 'b', label=\"Recall sur l'échantillon test\", color=\"red\")\n",
        "plt.title(\"Recall sur l'échantillon d'apprentissage et l'échantillon test\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label=\"Loss sur l'échantillon d'apprentissage\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Loss sur l'échantillon test\", color=\"red\")\n",
        "plt.title(\"Loss sur l'échantillon d'apprentissage et l'échantillon test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TC8-oY5DwVC5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC8-oY5DwVC5",
        "outputId": "f5d00ad6-a191-4d22-e500-1cc5fc68021f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss sur l'échantillon test: 1.064\n",
            "Accuracy sur l'échantillon test: 0.438\n",
            "Recall sur l'échantillon test: 0.706\n",
            "Precision sur l'échantillon test: 0.48\n",
            "F1-score sur l'échantillon test: 0.571\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy, recall_m, precision_m, f1_m = model_init.evaluate(X_test_permute.numpy(), Y_test.numpy(), verbose=0)\n",
        "print(\"Loss sur l'échantillon test: {}\".format(np.round(loss,3)))\n",
        "print(\"Accuracy sur l'échantillon test: {}\".format(np.round(accuracy,3)))\n",
        "print(\"Recall sur l'échantillon test: {}\".format(np.round(recall_m,3)))\n",
        "print(\"Precision sur l'échantillon test: {}\".format(np.round(precision_m,3)))\n",
        "print(\"F1-score sur l'échantillon test: {}\".format(np.round(f1_m,3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t7BtkwuiYbdE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7BtkwuiYbdE",
        "outputId": "a611c268-7d86-4111-c5e7-9d6a755d157d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fed92ee0820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 38s 38s/step\n"
          ]
        }
      ],
      "source": [
        "prob_predict = model_init.predict(X_test_permute.numpy())\n",
        "y_pred = (np.squeeze(prob_predict) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7w_RiZwBYxkp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w_RiZwBYxkp",
        "outputId": "569796ae-9622-443a-8d4a-801332048e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre d'images prédites avec panneaux: 25\n",
            "Nombre d'images prédites sans panneau: 7\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(y_pred, return_counts=True)\n",
        "res=dict(zip(unique, counts))\n",
        "print(\"Nombre d'images prédites avec panneaux: {}\".format(res[1]))\n",
        "print(\"Nombre d'images prédites sans panneau: {}\".format(res[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KDV7xwf1Y2uE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "KDV7xwf1Y2uE",
        "outputId": "581ed079-fba5-4445-9024-959229631cab"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "r = confusion_matrix(Y_test, y_pred)\n",
        "labels = [\"Vrais négatifs\",\"Faux Positifs\",\"Faux négatifs\",\"Vrais positifs\"]\n",
        "categories = [\"0\", \"1\"]\n",
        "make_confusion_matrix(r, \n",
        "                      group_names=labels,\n",
        "                      categories=categories, \n",
        "                      )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
