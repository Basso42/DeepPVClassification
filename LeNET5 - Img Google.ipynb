{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminologie: Définition des hyperparamètres du modèle\n",
    "\n",
    "* Hyperparamètre = Paramètre qui contrôle le processus d'apprentissage de notre réseau de neurones.\n",
    "\n",
    "* Batch Size = Hyperparamètre qui définit le nombres d'images traitées par notre algorithme avant de mettre à jour les paramètres du modèle (ses poids et ses biais). Plus le batck size est élevé, plus il faut de mémoire. En général, on utilise des batchs de taille 64, 128, 256 ou 512.\n",
    "\n",
    "* Epoch = Hyperparamètre qui définit le nombre d'itérations effectuées sur toutes les données d'apprentissage pour entraîner notre modèle.\n",
    "\n",
    "* Learning rate = Hyperparamètre qui contrôle la taille du pas effectué quand on se déplace vers le minimum de la fonction de perte. Si sa valeur est trop importante on risque d'osciller autour du minimum sans converger vers sa valeur et si le learning rate est trop faible on mettra trop de temps\n",
    "\n",
    "Exemple: si j'ai 1000 individus dans l'échantillon d'apprentissage, que batch_size = 500 et epoch = 2.\n",
    "* Première étape : On tire 500 individus dans l'échantillon d'apprentissage et on met à jour les paramètres de notre modèle.\n",
    "* Deuxième étape : On tire les 500 derniers individus de l'échantillon d'apprentissage et on met à jour les paramètres de notre modèle. La première itération du paramètre epoch est achevée.\n",
    "* Troisième étape : On tire à nouveau 500 individus dans l'échantillon d'apprentissage et on met à jour les paramètres de notre modèle (ces individus avaient déjà été tirés tirés dans l'étape un ou deux).\n",
    "* Quatrième étape : On tire les 500 derniers individus de l'échantillon d'apprentissage et on met à jour les paramètres de notre modèle. La seconde itération du paramètre epoch est achevée.\n",
    "\n",
    "Ainsi, dans notre exemple, il faut deux itérations pour réaliser un epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_attribution=LabelAttribution(path_image_google=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", \n",
    "                                   path_mask_google='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/mask/',\n",
    "                                   path_metadata='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/metadata.csv',\n",
    "                                   colonne_identifiant='identifiant',\n",
    "                                   path_export_train_test=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps\",\n",
    "                                   path_image_ign='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/ign/img',\n",
    "                                   path_mask_ign='C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/ign/mask/',\n",
    "                                   use_img_google=True,\n",
    "                                   use_img_ign=False\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_attribution.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le LeNET5 a été conçu pour prendre en entrée des images de dimension 28*28. On passe donc les images 400 x 400 en 28 x 28. On convertit ensuite ces dernières en tenseurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps/train_data.csv\"\n",
    "path_test=\"C:/Users/yanis/OneDrive/Documents/Projet Stat/statapps/test_data.csv\"\n",
    "\n",
    "transformed_train_dataset  = CustomImageDataset(path_train,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", transform=transforms.Compose([\n",
    "                                               transforms.Resize(28),\n",
    "                                               transforms.ToTensor(),\n",
    "                                           ]))\n",
    "transformed_test_dataset = CustomImageDataset(path_test,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\",\n",
    "                                            transform=transforms.Compose([\n",
    "                                               transforms.Resize(28),\n",
    "                                               transforms.ToTensor(),\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28, 3])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_dataset.__getitem__(0)[0].permute(1, 2, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images dans le train: 23045\n",
      "Nombre d'images dans le test: 5762\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre d'images dans le train: {}\".format(transformed_train_dataset.__len__()))\n",
    "print(\"Nombre d'images dans le test: {}\".format(transformed_test_dataset.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(transformed_train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(transformed_test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x28001d04790>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 3, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "#print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[2].squeeze()\n",
    "label = train_labels[2]\n",
    "plt.imshow(img.T)\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On normalise aussi les images: pour chaque chaque channel d'un tenseur, on met la moyenne à 0 et la variance à 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output[channel] = (input[channel] - mean[channel]) / std[channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne par channel: tensor([0.3651, 0.3608, 0.3116])\n",
      "Ecart-type par channel: tensor([0.1712, 0.1494, 0.1448])\n"
     ]
    }
   ],
   "source": [
    "mean, std = mean_std(train_dataloader)\n",
    "print(\"Moyenne par channel: {}\".format(mean))\n",
    "print(\"Ecart-type par channel: {}\".format(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on a utilisé des batches, les moyennes et écart-types calculés précédemment sont faux. On utilise, le code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne par channel: [0.3492565155029297, 0.35663557052612305, 0.3071684241294861]\n",
      "Ecart-type par channel: [0.16620320081710815, 0.14752358198165894, 0.14564624428749084]\n"
     ]
    }
   ],
   "source": [
    "mean_train, std_train = batch_mean_and_sd(train_dataloader)\n",
    "print(\"Moyenne par channel: {}\".format(mean_train.tolist()))\n",
    "print(\"Ecart-type par channel: {}\".format(std_train.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne par channel: [0.34999263286590576, 0.35766589641571045, 0.30810633301734924]\n",
      "Ecart-type par channel: [0.16761943697929382, 0.14885348081588745, 0.14731383323669434]\n"
     ]
    }
   ],
   "source": [
    "mean_test, std_test = batch_mean_and_sd(test_dataloader)\n",
    "print(\"Moyenne par channel: {}\".format(mean_test.tolist()))\n",
    "print(\"Ecart-type par channel: {}\".format(std_test.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On normalise les données. On ajoute aussi des rotations horizontales aléatoires. Avec probabilité 0.5, l'image est retournée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_dataset  = CustomImageDataset(path_train,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", transform=transforms.Compose([\n",
    "                                               transforms.Resize(28),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize(mean = mean_train.tolist(),\n",
    "                                                                    std= std_train.tolist()),\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "                                           ]))\n",
    "\n",
    "normalized_test_dataset  = CustomImageDataset(path_test,\"C:/Users/yanis/OneDrive/Documents/Projet Stat/Données/bdappv/google/img/\", transform=transforms.Compose([\n",
    "                                               transforms.Resize(28),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize(mean = mean_test.tolist(),\n",
    "                                                                    std= std_test.tolist()),\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "                                           ]))\n",
    "\n",
    "train_dataloader = DataLoader(normalized_train_dataset, batch_size=23045, shuffle=False)\n",
    "test_dataloader = DataLoader(normalized_test_dataset, batch_size=5762, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamétrisation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ère approche: Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pyimagesearch.com/2021/05/31/hyperparameter-tuning-for-deep-learning-with-scikit-learn-keras-and-tensorflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque hyperparamètre: batch_size, nb_epoch et learning rate, on définit un ensemble de valeur à tester. On teste toutes les combinaisons possibles et on choisit la meilleure.\n",
    "\n",
    "Avantages: permet de trouver les meilleurs hyperparamètres\n",
    "Limites: computation lente, souffre du fléau de la dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import BinaryCrossentropy\n",
    "loss_function_used = BinaryCrossentropy()\n",
    "\n",
    "def buildModel(learnRate=0.01, dropout=0.02):\n",
    "    model = keras.Sequential()\n",
    "    # Layer 1 Conv2D\n",
    "    model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28,28,3), padding=\"same\"))\n",
    "    # Layer 2 Pooling Layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    # Layer 3 Conv2D\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "    # Layer 4 Pooling Layer\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=120, activation='tanh'))\n",
    "    model.add(layers.Dense(units=84, activation='tanh'))\n",
    "    model.add(layers.Dense(units=2, activation=None))\n",
    "    model.compile(optimizer='sgd',loss=tf.keras.losses.binary_crossentropy,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    #model.compile(loss=loss_function_used, optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnRate = [1e-2, 1e-3, 1e-4]\n",
    "dropout = [0.3, 0.4, 0.5]\n",
    "batchSize = [4, 8, 16, 32, 64, 128, 256]\n",
    "epochs = [10, 20, 30, 40]\n",
    "\n",
    "grid = dict(\n",
    "\tlearnRate=learnRate,\n",
    "\tdropout=dropout,\n",
    "\tbatch_size=batchSize,\n",
    "\tepochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train=next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test=next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_permute=X_train.permute(0, 2, 3,1)\n",
    "X_test_permute=X_test.permute(0, 2, 3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2881/2881 [==============================] - 10s 3ms/step - loss: 7.4127 - accuracy: 0.4894 - val_loss: 7.6605 - val_accuracy: 0.5476\n",
      "Epoch 2/5\n",
      "2881/2881 [==============================] - 8s 3ms/step - loss: 7.6157 - accuracy: 0.5587 - val_loss: 7.6161 - val_accuracy: 0.5455\n",
      "Epoch 3/5\n",
      "2881/2881 [==============================] - 8s 3ms/step - loss: 7.6041 - accuracy: 0.5537 - val_loss: 7.5044 - val_accuracy: 0.5621\n",
      "Epoch 4/5\n",
      "2881/2881 [==============================] - 8s 3ms/step - loss: 7.4144 - accuracy: 0.5513 - val_loss: 7.3154 - val_accuracy: 0.5302\n",
      "Epoch 5/5\n",
      "2881/2881 [==============================] - 9s 3ms/step - loss: 7.1878 - accuracy: 0.5411 - val_loss: 6.9142 - val_accuracy: 0.5524\n"
     ]
    }
   ],
   "source": [
    "model=buildModel()\n",
    "\n",
    "H = model.fit(x=X_train_permute.numpy(), y=Y_train.numpy(),\n",
    "\tvalidation_data=(X_test_permute.numpy(), Y_test.numpy()),\n",
    "\tbatch_size=8,\n",
    "\tepochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 5.2984 - accuracy: 0.4602\n",
      "Epoch 2/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 4.5767 - accuracy: 0.4980\n",
      "Epoch 3/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 5.2884 - accuracy: 0.4647\n",
      "Epoch 4/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 5.2080 - accuracy: 0.4535\n",
      "Epoch 5/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 4.7391 - accuracy: 0.5814\n",
      "Epoch 6/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 4.9506 - accuracy: 0.5800\n",
      "Epoch 7/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 5.0245 - accuracy: 0.4920\n",
      "Epoch 8/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 6.9535 - accuracy: 0.4804\n",
      "Epoch 9/30\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 6.4864 - accuracy: 0.5219\n",
      "Epoch 10/30\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 5.9178 - accuracy: 0.4674\n",
      "Epoch 11/30\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 7.1545 - accuracy: 0.4420\n",
      "Epoch 12/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 7.4927 - accuracy: 0.4608\n",
      "Epoch 13/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 8.5400 - accuracy: 0.5579\n",
      "Epoch 14/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 8.4136 - accuracy: 0.5504\n",
      "Epoch 15/30\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 7.9534 - accuracy: 0.5136\n",
      "Epoch 16/30\n",
      "61/61 [==============================] - 2s 37ms/step - loss: 7.6645 - accuracy: 0.4951\n",
      "Epoch 17/30\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 7.5672 - accuracy: 0.4895\n",
      "Epoch 18/30\n",
      "61/61 [==============================] - 3s 41ms/step - loss: 7.3874 - accuracy: 0.4758\n",
      "Epoch 19/30\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 7.2038 - accuracy: 0.4633\n",
      "Epoch 20/30\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 6.0093 - accuracy: 0.3825\n",
      "Epoch 21/30\n",
      "61/61 [==============================] - 2s 37ms/step - loss: 5.5865 - accuracy: 0.3563\n",
      "Epoch 22/30\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 5.8039 - accuracy: 0.3729\n",
      "Epoch 23/30\n",
      "61/61 [==============================] - 3s 41ms/step - loss: 6.0837 - accuracy: 0.3936\n",
      "Epoch 24/30\n",
      "61/61 [==============================] - 3s 47ms/step - loss: 5.4601 - accuracy: 0.3535\n",
      "Epoch 25/30\n",
      "61/61 [==============================] - 3s 41ms/step - loss: 5.6398 - accuracy: 0.3591\n",
      "Epoch 26/30\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 5.5221 - accuracy: 0.3551\n",
      "Epoch 27/30\n",
      "61/61 [==============================] - 2s 35ms/step - loss: 5.1538 - accuracy: 0.3375\n",
      "Epoch 28/30\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 5.1443 - accuracy: 0.3372\n",
      "Epoch 29/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 5.1372 - accuracy: 0.3357\n",
      "Epoch 30/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 5.1560 - accuracy: 0.3383\n",
      "241/241 [==============================] - 1s 3ms/step\n",
      "Epoch 1/30\n",
      "61/61 [==============================] - 3s 38ms/step - loss: 5.4968 - accuracy: 0.5197\n",
      "Epoch 2/30\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 6.7396 - accuracy: 0.5097\n",
      "Epoch 3/30\n",
      "61/61 [==============================] - 2s 38ms/step - loss: 5.8476 - accuracy: 0.5177\n",
      "Epoch 4/30\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 6.7326 - accuracy: 0.5491\n",
      "Epoch 5/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 7.1350 - accuracy: 0.4957\n",
      "Epoch 6/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 5.9604 - accuracy: 0.4572\n",
      "Epoch 7/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 6.0136 - accuracy: 0.4483\n",
      "Epoch 8/30\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 7.4427 - accuracy: 0.4469\n",
      "Epoch 9/30\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 7.4555 - accuracy: 0.5106\n",
      "Epoch 10/30\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 7.5318 - accuracy: 0.5800\n",
      "Epoch 11/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 7.4932 - accuracy: 0.5574\n",
      "Epoch 12/30\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 7.5012 - accuracy: 0.5466\n",
      "Epoch 13/30\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 7.4874 - accuracy: 0.5492\n",
      "Epoch 14/30\n",
      "61/61 [==============================] - 3s 51ms/step - loss: 7.4516 - accuracy: 0.5494\n",
      "Epoch 15/30\n",
      "61/61 [==============================] - 3s 46ms/step - loss: 7.8592 - accuracy: 0.5435\n",
      "Epoch 16/30\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 8.3772 - accuracy: 0.4767\n",
      "Epoch 17/30\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 8.5181 - accuracy: 0.4605\n",
      "Epoch 18/30\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 8.4959 - accuracy: 0.4617\n",
      "Epoch 19/30\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 8.4443 - accuracy: 0.4676\n",
      "Epoch 20/30\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 8.2846 - accuracy: 0.4755\n",
      "Epoch 21/30\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 8.2621 - accuracy: 0.4709\n",
      "Epoch 22/30\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 8.2109 - accuracy: 0.4717\n",
      "Epoch 23/30\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 8.1703 - accuracy: 0.4730\n",
      "Epoch 24/30\n",
      "61/61 [==============================] - 4s 63ms/step - loss: 8.0974 - accuracy: 0.4786\n",
      "Epoch 25/30\n",
      "61/61 [==============================] - 4s 60ms/step - loss: 7.9508 - accuracy: 0.4875\n",
      "Epoch 26/30\n",
      "61/61 [==============================] - 3s 48ms/step - loss: 7.9362 - accuracy: 0.4879\n",
      "Epoch 27/30\n",
      "61/61 [==============================] - 3s 43ms/step - loss: 7.9951 - accuracy: 0.4899\n",
      "Epoch 28/30\n",
      "61/61 [==============================] - 2s 39ms/step - loss: 7.9496 - accuracy: 0.4925\n",
      "Epoch 29/30\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 7.9344 - accuracy: 0.4966\n",
      "Epoch 30/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 7.9104 - accuracy: 0.4968\n",
      "241/241 [==============================] - 1s 2ms/step\n",
      "Epoch 1/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 6.9634 - accuracy: 0.4156\n",
      "Epoch 2/30\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 6.8420 - accuracy: 0.4362\n",
      "Epoch 3/30\n",
      "61/61 [==============================] - 2s 38ms/step - loss: 6.5233 - accuracy: 0.4773\n",
      "Epoch 4/30\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 6.3622 - accuracy: 0.5141\n",
      "Epoch 5/30\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 6.4728 - accuracy: 0.5329\n",
      "Epoch 6/30\n",
      "61/61 [==============================] - 2s 41ms/step - loss: 6.6316 - accuracy: 0.5488\n",
      "Epoch 7/30\n",
      "61/61 [==============================] - 3s 44ms/step - loss: 7.1950 - accuracy: 0.5142\n",
      "Epoch 8/30\n",
      "61/61 [==============================] - 3s 47ms/step - loss: 6.8902 - accuracy: 0.5044\n",
      "Epoch 9/30\n",
      "61/61 [==============================] - 3s 43ms/step - loss: 7.5296 - accuracy: 0.4824\n",
      "Epoch 10/30\n",
      "61/61 [==============================] - 2s 40ms/step - loss: 7.6542 - accuracy: 0.4272\n",
      "Epoch 11/30\n",
      "61/61 [==============================] - 2s 38ms/step - loss: 7.6518 - accuracy: 0.4275\n",
      "Epoch 12/30\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 7.6456 - accuracy: 0.4289\n",
      "Epoch 13/30\n",
      "61/61 [==============================] - 2s 35ms/step - loss: 7.6411 - accuracy: 0.4267\n",
      "Epoch 14/30\n",
      "61/61 [==============================] - 3s 42ms/step - loss: 7.6433 - accuracy: 0.4293\n",
      "Epoch 15/30\n",
      "61/61 [==============================] - 3s 48ms/step - loss: 7.6433 - accuracy: 0.4324\n",
      "Epoch 16/30\n",
      "61/61 [==============================] - 4s 74ms/step - loss: 7.6387 - accuracy: 0.4311\n",
      "Epoch 17/30\n",
      "61/61 [==============================] - 4s 64ms/step - loss: 7.6339 - accuracy: 0.4314\n",
      "Epoch 18/30\n",
      "61/61 [==============================] - 3s 56ms/step - loss: 7.6311 - accuracy: 0.4302\n",
      "Epoch 19/30\n",
      "61/61 [==============================] - 3s 43ms/step - loss: 7.6212 - accuracy: 0.4298\n",
      "Epoch 20/30\n",
      "61/61 [==============================] - 2s 37ms/step - loss: 7.6195 - accuracy: 0.4216\n",
      "Epoch 21/30\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 7.6206 - accuracy: 0.4228\n",
      "Epoch 22/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 7.6173 - accuracy: 0.4232\n",
      "Epoch 23/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 7.6305 - accuracy: 0.4291\n",
      "Epoch 24/30\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 7.6292 - accuracy: 0.4289\n",
      "Epoch 25/30\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 7.6279 - accuracy: 0.4263\n",
      "Epoch 26/30\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 7.6200 - accuracy: 0.4309\n",
      "Epoch 27/30\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 7.6332 - accuracy: 0.4250\n",
      "Epoch 28/30\n",
      "61/61 [==============================] - 3s 41ms/step - loss: 7.6361 - accuracy: 0.4202\n",
      "Epoch 29/30\n",
      "61/61 [==============================] - 3s 53ms/step - loss: 7.6275 - accuracy: 0.4309\n",
      "Epoch 30/30\n",
      "61/61 [==============================] - 3s 51ms/step - loss: 7.6152 - accuracy: 0.4388\n",
      "241/241 [==============================] - 2s 6ms/step\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 4s 28ms/step - loss: 4.6289 - accuracy: 0.4549\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 4.2144 - accuracy: 0.4803\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 4.2142 - accuracy: 0.4573\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 7.4489 - accuracy: 0.4910\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 8.1603 - accuracy: 0.4556\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 8.0263 - accuracy: 0.4601\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 4s 29ms/step - loss: 7.8710 - accuracy: 0.4599\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 11s 90ms/step - loss: 7.6159 - accuracy: 0.4685\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 8.0637 - accuracy: 0.4571\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 5s 39ms/step - loss: 7.7805 - accuracy: 0.4543\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 7.1356 - accuracy: 0.4634\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 6.8405 - accuracy: 0.4694\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 7.1609 - accuracy: 0.4314\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 7.4063 - accuracy: 0.4273\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 7.1406 - accuracy: 0.4197\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 6.8619 - accuracy: 0.4204\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 6.6192 - accuracy: 0.4671\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 7.2332 - accuracy: 0.4663\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 6.9475 - accuracy: 0.5066\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 6.8359 - accuracy: 0.5403\n",
      "241/241 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 4s 20ms/step - loss: 3.1089 - accuracy: 0.4379\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 2.4125 - accuracy: 0.4732\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 5.8714 - accuracy: 0.5495\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 6.4178 - accuracy: 0.4554\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 7.0791 - accuracy: 0.5162\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 7.2756 - accuracy: 0.5158\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 6.9358 - accuracy: 0.5434\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 6.5716 - accuracy: 0.6016\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 5.8933 - accuracy: 0.5407\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 7.3417 - accuracy: 0.5457\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 7.7515 - accuracy: 0.5434\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 7.4735 - accuracy: 0.5446\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 7.2138 - accuracy: 0.5355\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 7.3622 - accuracy: 0.4914\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 2s 21ms/step - loss: 7.6538 - accuracy: 0.4474\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 7.6544 - accuracy: 0.4670\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 7.6773 - accuracy: 0.5166\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 7.6286 - accuracy: 0.5216\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 7.5064 - accuracy: 0.5266\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 6.9897 - accuracy: 0.5515\n",
      "241/241 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 3.3892 - accuracy: 0.4673\n",
      "Epoch 2/20\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 5.8707 - accuracy: 0.4604\n",
      "Epoch 3/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 6.6746 - accuracy: 0.4393\n",
      "Epoch 4/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 6.6277 - accuracy: 0.4152\n",
      "Epoch 5/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 6.5151 - accuracy: 0.3938\n",
      "Epoch 6/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 6.5218 - accuracy: 0.4547\n",
      "Epoch 7/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 7.6450 - accuracy: 0.5430\n",
      "Epoch 8/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 7.5566 - accuracy: 0.5221\n",
      "Epoch 9/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 7.5978 - accuracy: 0.6039\n",
      "Epoch 10/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 7.7239 - accuracy: 0.5437\n",
      "Epoch 11/20\n",
      "121/121 [==============================] - 2s 21ms/step - loss: 7.6510 - accuracy: 0.5194\n",
      "Epoch 12/20\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 7.6449 - accuracy: 0.5199\n",
      "Epoch 13/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 7.6454 - accuracy: 0.5208\n",
      "Epoch 14/20\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 7.5771 - accuracy: 0.4772\n",
      "Epoch 15/20\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 7.5423 - accuracy: 0.4785\n",
      "Epoch 16/20\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 7.5117 - accuracy: 0.4682\n",
      "Epoch 17/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 7.4492 - accuracy: 0.4546\n",
      "Epoch 18/20\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 7.2834 - accuracy: 0.4646\n",
      "Epoch 19/20\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 6.7158 - accuracy: 0.4599\n",
      "Epoch 20/20\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 6.6642 - accuracy: 0.4566\n",
      "241/241 [==============================] - 2s 6ms/step\n",
      "Epoch 1/10\n",
      "121/121 [==============================] - 6s 38ms/step - loss: 5.7856 - accuracy: 0.5144\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 6.1343 - accuracy: 0.5250\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 3s 29ms/step - loss: 6.9733 - accuracy: 0.4702\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 5.9253 - accuracy: 0.4856\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 8.1806 - accuracy: 0.4694\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 8.5416 - accuracy: 0.4587\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 8.9020 - accuracy: 0.4471\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 8.5543 - accuracy: 0.4418\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 7.4226 - accuracy: 0.4137\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 7.6841 - accuracy: 0.4661\n",
      "241/241 [==============================] - 1s 5ms/step\n",
      "Epoch 1/10\n",
      "121/121 [==============================] - 4s 23ms/step - loss: 7.3040 - accuracy: 0.4907\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 2s 21ms/step - loss: 7.6152 - accuracy: 0.4956\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 7.6820 - accuracy: 0.4871\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 7.6038 - accuracy: 0.4886\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 7.6361 - accuracy: 0.4845\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 7.6789 - accuracy: 0.4808\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 7.6890 - accuracy: 0.4748\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 7.6812 - accuracy: 0.4757\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 7.6795 - accuracy: 0.4760\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 7.6788 - accuracy: 0.4762\n",
      "241/241 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "121/121 [==============================] - 3s 18ms/step - loss: 5.9086 - accuracy: 0.5005\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 6.1992 - accuracy: 0.5500\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 6.6982 - accuracy: 0.4546\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 5.8262 - accuracy: 0.3666\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 5.4592 - accuracy: 0.4129\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 7.1752 - accuracy: 0.4666\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 7.1559 - accuracy: 0.4660\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 6.9144 - accuracy: 0.4559\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 6.4930 - accuracy: 0.4396\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 6.1850 - accuracy: 0.4139\n",
      "241/241 [==============================] - 1s 3ms/step\n",
      "Epoch 1/30\n",
      "3841/3841 [==============================] - 9s 2ms/step - loss: 6.5859 - accuracy: 0.5722\n",
      "Epoch 2/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.2559 - accuracy: 0.5087\n",
      "Epoch 3/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.1769 - accuracy: 0.4762\n",
      "Epoch 4/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.7187 - accuracy: 0.5368\n",
      "Epoch 5/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.4223 - accuracy: 0.5676\n",
      "Epoch 6/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.3412 - accuracy: 0.5250\n",
      "Epoch 7/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.0813 - accuracy: 0.5292\n",
      "Epoch 8/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.5297 - accuracy: 0.5295\n",
      "Epoch 9/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.6063 - accuracy: 0.5036\n",
      "Epoch 10/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.3056 - accuracy: 0.5033\n",
      "Epoch 11/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.0906 - accuracy: 0.4949\n",
      "Epoch 12/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.2516 - accuracy: 0.4021\n",
      "Epoch 13/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.0701 - accuracy: 0.4531\n",
      "Epoch 14/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.9902 - accuracy: 0.4648\n",
      "Epoch 15/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.6859 - accuracy: 0.4784\n",
      "Epoch 16/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.8279 - accuracy: 0.4830\n",
      "Epoch 17/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 6.5903 - accuracy: 0.4813\n",
      "Epoch 18/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.0160 - accuracy: 0.4878\n",
      "Epoch 19/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.5649 - accuracy: 0.4948\n",
      "Epoch 20/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.5664 - accuracy: 0.4913\n",
      "Epoch 21/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.5652 - accuracy: 0.4931\n",
      "Epoch 22/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.5585 - accuracy: 0.4837\n",
      "Epoch 23/30\n",
      "3841/3841 [==============================] - 8s 2ms/step - loss: 7.5544 - accuracy: 0.4816\n",
      "Epoch 24/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.5426 - accuracy: 0.4805\n",
      "Epoch 25/30\n",
      "3841/3841 [==============================] - 7s 2ms/step - loss: 7.5189 - accuracy: 0.4797\n",
      "Epoch 26/30\n",
      "3339/3841 [=========================>....] - ETA: 0s - loss: 7.5133 - accuracy: 0.4805"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[252], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m scoring \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mLog loss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mneg_log_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBal Acc\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mbalanced_accuracy\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m      9\u001b[0m searcher \u001b[39m=\u001b[39m RandomizedSearchCV(estimator\u001b[39m=\u001b[39mmodel, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, param_distributions\u001b[39m=\u001b[39mgrid, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m searchResults \u001b[39m=\u001b[39m searcher\u001b[39m.\u001b[39;49mfit(X_train_permute\u001b[39m.\u001b[39;49mnumpy(), Y_train\u001b[39m.\u001b[39;49mnumpy())\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1765\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1766\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1767\u001b[0m         ParameterSampler(\n\u001b[0;32m   1768\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1769\u001b[0m         )\n\u001b[0;32m   1770\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n\u001b[0;32m    841\u001b[0m         X,\n\u001b[0;32m    842\u001b[0m         y,\n\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    849\u001b[0m     )\n\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:248\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape for y: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(y\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    247\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:175\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m fit_args \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(Sequential\u001b[39m.\u001b[39mfit))\n\u001b[0;32m    173\u001b[0m fit_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 175\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = KerasClassifier(build_fn=buildModel, verbose=1)\n",
    "#grid = GridSearchCV(estimator=model, param_grid=hyperMatrix)\n",
    "\n",
    "scoring = {'Log loss': 'neg_log_loss', 'F1': 'f1', 'Bal Acc': 'balanced_accuracy'}\n",
    "\n",
    "searcher = RandomizedSearchCV(estimator=model, cv=3, param_distributions=grid, scoring=\"accuracy\")\n",
    "searchResults = searcher.fit(X_train_permute.numpy(), Y_train.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize grid search information\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\n",
    "\tbestParams))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
